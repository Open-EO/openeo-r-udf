---
title: "R-UDF-Introduction"
author: "Florian Lahn"
date: "2019-11-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## UDF

### Prerequisite
You need to have a running UDF service instance. Either via RStudio and its integrated plumber API support. Or you can run the service by creating a container from the Docker image.
You have cloned the repository or downloaded the JSON files and this file in `/examples`.

### Example Data
The example data is a Sentinel-2 L1C subset for 3 timesteps, 13 bands and 300 x 300 pixel spatial resolution. The single bands are upscaled to the highest available resolution applying nearest neighbor interpolation. This scene is provided as plain text JSON files as `RasterCollectionTile` and `Hypercube`. The current data models can be viewed [here (Version 0.1pre-alpha)](https://open-eo.github.io/openeo-udf/api_docs/).

### Local run_udf function
```{r}
library(jsonlite)
library(httr)

# data is the parsed JSON (a list)
# code is quoted R code
run_udf = function(data, code, host="http://localhost", port=NULL, debug = FALSE, download_info = FALSE) {
  if (is.character(data)) {
    data = read_json(data, simplifyVector = TRUE)
  }
  
  if (is.call(code)) {
    code = paste(deparse(code),collapse = "\n")
  } else if (is.character(code)) {
    if (file.exists(code)) {
      # if valid file path open file and attach
      code = readChar(code, file.info(code)$size)
    }    
  }
  
  
  
  payload = list(
    code = list(
      source = code,
      language = "R"),
    data = data
  )
  
  if (is.null(port)) {
    url = paste0(host,"/udf")
  } else {
    url = paste0(host,":",port,"/udf")
  }
  
  
  
  options(digits.secs=3)
  start = Sys.time()
  res = httr::POST(url,config=add_headers(Date=start),body=toJSON(payload,auto_unbox = TRUE),encode=c("json"))
  end = Sys.time()
  if (debug) {
    print(end-start)
  }
  
  if (download_info) {
    cat("Download time:\n")
    print(end-as_datetime(res$date,tz=Sys.timezone()))
  }
  
  if (res$status > 400) {
    message(paste0("[Server-ERROR] ",content(res,as = "parsed")$message))
  } else {
    return(content(res,as = "text",encoding = "UTF-8"))
  }
  
}
```

With this function you can upload a payload to the UDF service by specifying `host`, `port`, `code` and `data`. If you are not interested in benchmarking you can leave `debug` and `download_info` with the default values. The latter two parameters return the time taken for the complete UDF request (debug) and the time for downloading the result data set.

You can pass either the path to the json file containing the data (e.g. one of the provided files) or you can pass a already imported JSON file (e.g. the result after using `jsonlite::read_json`). The code shall be provided as a quoted command block. To develop the UDF script you need to know that the variable `data` is provided as a `stars` object - always. Internally in the UDF service, a function is build with the parameter `data` and the body of that function is then replaced with the provided code. The result of the script needs to be also a `stars` object.

```{r}
script = quote({
  all_dim = names(dim(data))
  ndvi_result = st_apply(data, FUN = function(X,...) {
    (X[8]-X[4])/(X[8]+X[4])
  }, MARGIN = all_dim[-which(all_dim=="band")])
  
  all_dim = names(dim(ndvi_result))
  min_ndvi = st_apply(ndvi_result,FUN = min, MARGIN = all_dim[-which(all_dim=="time")])

  min_ndvi
})
```

The script is merely an example and can be optimized. It calculates the minimum NDVI over the given data set.

```{r,  eval=FALSE}
port = 5555 # to be modified according to your setup
host = "http://localhost" # modify regarding your settings
result_with_rct = jsonlite::fromJSON(run_udf(data = "raster_collection_tile.json",code = script,host=host,port=port),simplifyVector = TRUE)
result_with_cube = jsonlite::fromJSON(run_udf(data = "hypercube.json",code = script,host=host,port=port),simplifyVector = TRUE)
```

The result of the run_udf is a JSON string that can be translated into an R object. The type of the object is a `HyperCube`.